## 前言

距离写上一篇[爬虫工程师的自我修养之基础模块](https://worldwonderer.github.io/%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9D%97/)已经过去大半年了，接着来填坑系统架构。现在大多数爬虫工程师似乎都在往逆向方向发展，传统系统架构相关的文章反而销声匿迹了。这里我抛砖引玉，谈一谈我在爬虫系统架构相关的理解

## 框架
scrapy已有10年的历史，pyspider从2014年发布0.1.0版本到现在竟也有7年了。无论什么爬虫框架，都绕不开调度、下载和解析，总体结构上不会有太大的差异，在这上面可玩的花样很少。这里我推荐一种框架的实现：celery+requests

### 异步的好也“不好”
异步好在哪自不用说，所谓的“不好”是说什么呢？2021年了，还是能看到有爬虫工程师往scrapy/pyspider的callback解析部分中加io阻塞型代码，问就是不知道会阻塞，问就是这么写简单。可能从最初的一两行的时候没有太大影响，日子久了之后整个爬虫系统非常缓慢。另外tornado还好一些，twisted实在难以称为主流。使用requests，就不用去考虑异步的问题，celery负责在整体上对爬取任务进行加速

### 调度缺失
现有爬虫框架的调度部分相对比较薄弱，其余提供的核心能力在于异步下载能力。但大型爬虫系统中，我们更需要强大的调度能力，如资源分配，优先级控制

### 分布式与多爬虫管理
首先分布式方面，scrapy框架本身是偏向于单机的，虽然有scrapy-redis的加持，但分布式的调度部分功能十分匮乏。再来看多爬虫的管理部分，scrapyd就更是惨不忍睹了，在进程的维度对scrapy进行启停，并且近两年没有大的更新。celery本身就具有分布式的特征，作为专业的分布式任务调度和处理框架，无论是task还是worker层面提供的控制力是足够的

### Celery脚手架
待补充

## 调度
待补充

## 存储
待补充

## 监控
待补充

## 对外能力
待补充

## 架构图

最后附上最终的架构图

![](../assets/images/20210117/0.png)
